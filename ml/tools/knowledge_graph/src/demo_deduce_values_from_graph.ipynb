{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, StorageContext, PropertyGraphIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.readers.docling import DoclingReader\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "\n",
    "from llama_index.core.graph_stores import SimplePropertyGraphStore, PropertyGraphStore\n",
    "from llama_index.core.graph_stores.types import LabelledPropertyGraph, EntityNode, Relation, ChunkNode\n",
    "from uuid import uuid4\n",
    "from llama_index.core.extractors import KeywordExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dfe3287ea849378014744d50116190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='610px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "company = EntityNode(label=\"COMPANY\", name=\"Applied Materials\")\n",
    "num_apples = EntityNode(label=\"VALUE\", name=\"number of apples\")\n",
    "apples = EntityNode(label=\"VALUE\", name=\"apples\")\n",
    "num_pears = EntityNode(label=\"VALUE\", name=\"number of pears\")\n",
    "pears = EntityNode(label=\"VALUE\", name=\"pears\")\n",
    "num_bananas = EntityNode(label=\"VALUE\", name=\"number of bananas\")\n",
    "bananas = EntityNode(label=\"VALUE\", name=\"bananas\")\n",
    "num_apricots = EntityNode(label=\"VALUE\", name=\"number of apricots\")\n",
    "apricots = EntityNode(label=\"VALUE\", name=\"apricots\")\n",
    "eq_apple_pear = EntityNode(label=\"EQUATION\", name=\"number of bananas = number of apples - number of pears\")\n",
    "eq_banana_apricot = EntityNode(label=\"EQUATION\", name=\"number of apricots = number of bananas\")\n",
    "entities = [\n",
    "    company, \n",
    "    apples, pears, bananas, apricots,\n",
    "    num_apples, num_pears, num_bananas, num_apricots,\n",
    "    eq_apple_pear, eq_banana_apricot,\n",
    "]\n",
    "\n",
    "relations_kpi = [\n",
    "    Relation(label=\"HAS_PROPERTY\", source_id=company.id, target_id=num_apples.id), \n",
    "    Relation(label=\"HAS_PROPERTY\", source_id=company.id, target_id=num_pears.id), \n",
    "    Relation(label=\"HAS_PROPERTY\", source_id=company.id, target_id=num_bananas.id),\n",
    "    Relation(label=\"HAS_PROPERTY\", source_id=company.id, target_id=num_apricots.id),\n",
    "    # alias relations\n",
    "    Relation(label=\"SAME_AS\", source_id=bananas.id, target_id=num_bananas.id),\n",
    "    Relation(label=\"SAME_AS\", source_id=num_bananas.id, target_id=bananas.id),\n",
    "    Relation(label=\"SAME_AS\", source_id=apples.id, target_id=num_apples.id),\n",
    "    Relation(label=\"SAME_AS\", source_id=num_apples.id, target_id=apples.id),\n",
    "    Relation(label=\"ALIAS_OF\", source_id=pears.id, target_id=num_pears.id),\n",
    "    Relation(label=\"ALIAS_OF\", source_id=num_pears.id, target_id=pears.id),\n",
    "    Relation(label=\"ALIAS_OF\", source_id=apricots.id, target_id=num_apricots.id),\n",
    "    Relation(label=\"ALIAS_OF\", source_id=num_apricots.id, target_id=apricots.id),\n",
    "    # equation bananas = apricots\n",
    "    Relation(label=\"HAS_EQUATION\", source_id=num_bananas.id, target_id=eq_banana_apricot.id), \n",
    "    Relation(label=\"HAS_EQUATION\", source_id=num_apricots.id, target_id=eq_banana_apricot.id),\n",
    "    Relation(label=\"DEPENDS_ON\", source_id=eq_banana_apricot.id, target_id=bananas.id), \n",
    "    Relation(label=\"DEPENDS_ON\", source_id=eq_banana_apricot.id, target_id=apricots.id), \n",
    "    # equation bananas = apples - pears\n",
    "    Relation(label=\"HAS_EQUATION\", source_id=bananas.id, target_id=eq_apple_pear.id),\n",
    "    Relation(label=\"HAS_EQUATION\", source_id=apples.id, target_id=eq_apple_pear.id),\n",
    "    Relation(label=\"HAS_EQUATION\", source_id=pears.id, target_id=eq_apple_pear.id),\n",
    "    Relation(label=\"DEPENDS_ON\", source_id=eq_apple_pear.id, target_id=bananas.id),\n",
    "    Relation(label=\"DEPENDS_ON\", source_id=eq_apple_pear.id, target_id=apples.id), \n",
    "    Relation(label=\"DEPENDS_ON\", source_id=eq_apple_pear.id, target_id=pears.id),\n",
    "]\n",
    "\n",
    "R_EQUATION = {\"HAS_EQUATION\", \"COMPUTED_BY\", \"EQUALS\"}\n",
    "R_ALIAS = {\"ALIAS_OF\", \"SAME_AS\"}\n",
    "R_DEPENDS = {\"DEPENDS_ON\", \"USES\", \"INPUT\"}\n",
    "\n",
    "kgraph = SimplePropertyGraphStore()\n",
    "kgraph.upsert_nodes(entities)\n",
    "kgraph.upsert_relations(relations_kpi)\n",
    "\n",
    "kgraph.show_jupyter_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e085f526273b4e87919bdbd01dfc6419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='630px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [\n",
    "    TextNode(text=\"the company Applied Materials (AMAT) has 100 apples\"), \n",
    "    TextNode(text=\"the company Applied Materials (AMAT) has 10 pears\")\n",
    "]\n",
    "\n",
    "\n",
    "kgraph.upsert_llama_nodes(sentences)\n",
    "\n",
    "kgraph.show_jupyter_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(EntityNode(label='VALUE', embedding=None, properties={}, name='number of bananas'),\n",
       "  Relation(label='SAME_AS', source_id='number of bananas', target_id='bananas', properties={}),\n",
       "  EntityNode(label='VALUE', embedding=None, properties={}, name='bananas')),\n",
       " (EntityNode(label='VALUE', embedding=None, properties={}, name='bananas'),\n",
       "  Relation(label='SAME_AS', source_id='bananas', target_id='number of bananas', properties={}),\n",
       "  EntityNode(label='VALUE', embedding=None, properties={}, name='number of bananas'))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kgraph.get_triplets(\n",
    "    ids=[bananas.id],\n",
    "    relation_names=list(R_ALIAS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding relations between number of apples and the company Applied Materials (AMAT) has 100 apples\n",
      "adding relations between apples and the company Applied Materials (AMAT) has 100 apples\n",
      "adding relations between number of pears and the company Applied Materials (AMAT) has 10 pears\n",
      "adding relations between pears and the company Applied Materials (AMAT) has 10 pears\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f576f0121eb24e5b8cedf4e502eff7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='630px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO tune extractor prompt so that focus on business metrics words\n",
    "kw_extractor = KeywordExtractor(llm=None, keywords=6)\n",
    "\n",
    "relations: list[Relation] = []\n",
    "\n",
    "name_to_id = {\n",
    "    node.name.lower(): node.id\n",
    "    for node in kgraph.graph.get_all_nodes()\n",
    "    if node.label in {\"VALUE\", \"EQUATION\"}\n",
    "}\n",
    "\n",
    "def get_alias_nodes(node_id: str) -> set[str]:\n",
    "    \"\"\"Get all nodes connected via a relation in R_ALIAS.\"\"\"\n",
    "    connected = {node_id}\n",
    "\n",
    "    for sub, _, obj in kgraph.get_triplets(ids=[node_id], relation_names=list(R_ALIAS)):\n",
    "        connected.add(sub.id)\n",
    "        connected.add(obj.id)\n",
    "\n",
    "    return connected\n",
    "\n",
    "all_keywords = kw_extractor.extract(sentences)\n",
    "# TODO can run async\n",
    "for (sentence, keywords) in zip(sentences, all_keywords):\n",
    "\n",
    "    keywords_clean = [k.strip().lower() for k in keywords[\"excerpt_keywords\"].split(\",\")]\n",
    "\n",
    "    for kw in keywords_clean:\n",
    "        if kw not in name_to_id.keys():\n",
    "            continue  # skip keywords that have no VALUE/EQUATION node\n",
    "\n",
    "        ent_id = name_to_id[kw]\n",
    "        # add relation to all alias nodes\n",
    "        for node_id in get_alias_nodes(ent_id):\n",
    "            print(f\"adding relations between {node_id} and {sentence.text}\")\n",
    "            relations.append(\n",
    "                Relation(\n",
    "                    source_id=node_id,               # VALUE / EQUATION node id\n",
    "                    target_id=sentence.id_,               # sentence node id\n",
    "                    label=\"HAS_SENTENCE\",        # custom relation label\n",
    "                    properties={\"source\": \"keyword_link\"},\n",
    "                )\n",
    "            )\n",
    "        # TODO make sure that when later find sentence through alias, the LLM knows the alias\n",
    "        # probably by passing information as property\n",
    "\n",
    "if relations:\n",
    "    kgraph.upsert_relations(relations)\n",
    "\n",
    "kgraph.show_jupyter_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(EntityNode(label='VALUE', embedding=None, properties={}, name='apricots'), Relation(label='ALIAS_OF', source_id='apricots', target_id='number of apricots', properties={}), EntityNode(label='VALUE', embedding=None, properties={}, name='number of apricots'))\n",
      "(EntityNode(label='EQUATION', embedding=None, properties={}, name='number of apricots = number of bananas'), Relation(label='DEPENDS_ON', source_id='number of apricots = number of bananas', target_id='apricots', properties={}), EntityNode(label='VALUE', embedding=None, properties={}, name='apricots'))\n",
      "(EntityNode(label='VALUE', embedding=None, properties={}, name='number of apricots'), Relation(label='ALIAS_OF', source_id='number of apricots', target_id='apricots', properties={}), EntityNode(label='VALUE', embedding=None, properties={}, name='apricots'))\n",
      "dict_items([('apples', 'apples'), ('pears', 'pears'), ('bananas', 'bananas'), ('apricots', 'apricots'), ('number of apples', 'number of apples'), ('number of pears', 'number of pears'), ('number of bananas', 'number of bananas'), ('number of apricots', 'number of apricots'), ('number of bananas = number of apples - number of pears', 'number of bananas = number of apples - number of pears'), ('number of apricots = number of bananas', 'number of apricots = number of bananas')])\n"
     ]
    }
   ],
   "source": [
    "map = kgraph.get_rel_map(\n",
    "    graph_nodes=[apricots],\n",
    "    depth=1,\n",
    "    limit=30,\n",
    "    ignore_rels=None,\n",
    ")\n",
    "\n",
    "[print(rel) for rel in map]\n",
    "\n",
    "query_str = \"how many apricots does the company have?\"\n",
    "qstr = query_str.lower()\n",
    "seeds_id = [node_id for name, node_id in name_to_id.items() if name in qstr]\n",
    "\n",
    "print(name_to_id.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the company Applied Materials (AMAT) has 100 apples\n"
     ]
    }
   ],
   "source": [
    "sent_id = sentences[0].id_\n",
    "\n",
    "sent_raw = kgraph.get(ids=[sent_id])[0]\n",
    "\n",
    "print(sent_raw.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Optional, Union, Any\n",
    "from llama_index.core.base.base_retriever import BaseRetriever\n",
    "from llama_index.core.schema import QueryBundle, NodeWithScore, TextNode\n",
    "# from llama_index.core.graph_stores import PropertyGraphStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.query_engine import BaseQueryEngine\n",
    "# from llama_index.core.llms import LLM, OpenAI # Using OpenAI as an example LLM, replace with your actual LLM\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.response import Response\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "\n",
    "# Assuming 'sentences' is defined and used to initialize sent_index\n",
    "sent_index = VectorStoreIndex(sentences) # This line is from your original code, keep it if applicable\n",
    "\n",
    "class CustomGraphRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    Recursive VALUE→EQUATION→VALUE search.\n",
    "    Outputs terminal VALUE nodes with supporting sentences and all encountered EQUATION nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- relation labels (adapt to your own schema) -------------\n",
    "    R_HAS_SENTENCE = {\"HAS_SENTENCE\"}\n",
    "    R_EQUATION     = {\"HAS_EQUATION\", \"COMPUTED_BY\", \"EQUALS\"} # e.g., VALUE -[COMPUTED_BY]-> EQUATION\n",
    "    R_DEPENDS      = {\"DEPENDS_ON\", \"USES\", \"INPUT\"} # e.g., EQUATION -[DEPENDS_ON]-> VALUE\n",
    "    R_ALIAS        = {\"ALIAS_OF\", \"SAME_AS\"}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph_store: PropertyGraphStore,\n",
    "        sentence_index: VectorStoreIndex, # This might be used for initial seeding, but not directly in the current _collect logic.\n",
    "        name_to_id: Dict[str, str],\n",
    "        max_depth: int = 5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._graph = graph_store\n",
    "        self._sidx = sentence_index # Kept for consistency, though not used in direct retrieval.\n",
    "        # map metric names to VALUE node IDs\n",
    "        self._name2id = {k.lower(): v for k, v in name_to_id.items()}\n",
    "        self._max_depth = max_depth\n",
    "\n",
    "    # ----------------- helper: outgoing triples ------------------\n",
    "    def _outgoing(self, src_id: str, rel_set: Optional[Set[str]] = None):\n",
    "        \"\"\"Yields (subject, relation, object) triples where subject.id == src_id.\"\"\"\n",
    "        for subj, rel, obj in self._graph.get_triplets(ids=[src_id]):\n",
    "            if subj.id != src_id:\n",
    "                continue\n",
    "            if rel_set is not None and rel.id not in rel_set:\n",
    "                continue\n",
    "            yield subj, rel, obj\n",
    "\n",
    "    # ----------------- recursive collection ---------------------\n",
    "    def _collect(\n",
    "        self,\n",
    "        node_id: str,\n",
    "        depth: int,\n",
    "        seen_vals: Set[str], # Tracks visited VALUE node IDs to prevent cycles and redundant processing\n",
    "        seen_eqs_ids: Set[str], # Tracks EQUATION node IDs that have already been added to output\n",
    "        terminal_value_nodes_output: List[NodeWithScore],\n",
    "        equation_nodes_output: List[NodeWithScore],\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Recursively collects relevant VALUE nodes with supporting sentences and EQUATION nodes.\n",
    "        \"\"\"\n",
    "        if depth > self._max_depth:\n",
    "            return\n",
    "\n",
    "        raw_nodes = self._graph.get(ids=[node_id])\n",
    "        if not raw_nodes:\n",
    "            return\n",
    "        raw_node = raw_nodes[0] # Get the actual node object (EntityNode or ChunkNode)\n",
    "\n",
    "        score = 1.0 / (depth + 1) # Simple scoring based on depth\n",
    "\n",
    "        # --- Handle VALUE nodes ---\n",
    "        if raw_node.label == \"VALUE\":\n",
    "            if node_id in seen_vals:\n",
    "                return # Already processed this VALUE node in a way that prevents re-visiting this path\n",
    "\n",
    "            # Add to seen_vals *before* exploring paths from this node to prevent infinite loops\n",
    "            seen_vals.add(node_id)\n",
    "\n",
    "            # 1. Check for direct evidence (sentences) for this VALUE node\n",
    "            sent_edges = list(self._outgoing(node_id, self.R_HAS_SENTENCE))\n",
    "            if sent_edges:\n",
    "                lines = []\n",
    "                for _, _, sent_chunk_node_obj in sent_edges: # sent_chunk_node_obj is the ChunkNode entity\n",
    "                    sent_raw_nodes = self._graph.get(ids=[sent_chunk_node_obj.id])\n",
    "                    if sent_raw_nodes and hasattr(sent_raw_nodes[0], 'text') and sent_raw_nodes[0].text:\n",
    "                        lines.append(f\"- {sent_raw_nodes[0].text}\")\n",
    "                text = (\n",
    "                    f\"The following information likely contains the value of {raw_node.name}:\\n\"\n",
    "                    + \"\\n\".join(lines)\n",
    "                )\n",
    "                wrapped = TextNode(text=text, id_=node_id, metadata={\"node_type\": \"VALUE_SENTENCE\", \"original_label\": raw_node.label})\n",
    "                terminal_value_nodes_output.append(NodeWithScore(node=wrapped, score=score))\n",
    "                return # This is a terminal VALUE node (direct evidence found), stop further search down this path\n",
    "\n",
    "            # 2. If no direct sentences, look for an equation that computes this VALUE\n",
    "            # Assuming VALUE -[R_EQUATION]-> EQUATION\n",
    "            eq_edges_from_value = list(self._outgoing(node_id, self.R_EQUATION))\n",
    "            for _, _, eq_obj in eq_edges_from_value:\n",
    "                if eq_obj.label == \"EQUATION\": # Ensure the object is an EQUATION node\n",
    "                    self._collect(eq_obj.id, depth + 1, seen_vals, seen_eqs_ids, terminal_value_nodes_output, equation_nodes_output)\n",
    "\n",
    "            # 3. Alias hop for VALUE nodes (can lead to another VALUE node that might have sentences/equations)\n",
    "            for _, _, alias_obj in self._outgoing(node_id, self.R_ALIAS):\n",
    "                if alias_obj.label == \"VALUE\": # Ensure the object of alias is also a VALUE node\n",
    "                    # Alias links should not increase depth, as it's the same logical entity\n",
    "                    self._collect(alias_obj.id, depth, seen_vals, seen_eqs_ids, terminal_value_nodes_output, equation_nodes_output)\n",
    "\n",
    "        # --- Handle EQUATION nodes ---\n",
    "        elif raw_node.label == \"EQUATION\":\n",
    "            if node_id in seen_eqs_ids:\n",
    "                return # Already processed and added this EQUATION node to the output\n",
    "\n",
    "            # Add the equation to the output list. Assuming equation text is stored in raw_node.name\n",
    "            textnode = TextNode(text=raw_node.name, id_=node_id, metadata={\"node_type\": \"EQUATION\", \"original_label\": raw_node.label})\n",
    "            equation_nodes_output.append(NodeWithScore(node=textnode, score=score))\n",
    "            seen_eqs_ids.add(node_id) # Mark this equation as processed for output\n",
    "\n",
    "            # Recurse on every dependency (input VALUE node) of this equation\n",
    "            # Assuming EQUATION -[R_DEPENDS]-> VALUE\n",
    "            dep_edges = list(self._outgoing(node_id, self.R_DEPENDS))\n",
    "            for _, _, dep_obj in dep_edges:\n",
    "                if dep_obj.label == \"VALUE\": # Ensure the object of dependency is a VALUE node\n",
    "                    self._collect(dep_obj.id, depth + 1, seen_vals, seen_eqs_ids, terminal_value_nodes_output, equation_nodes_output)\n",
    "        else:\n",
    "            pass # Ignore other node types for now.\n",
    "\n",
    "    # ----------------- public API --------------------------------\n",
    "    def _retrieve(\n",
    "        self,\n",
    "        query: QueryBundle,\n",
    "    ) -> List[NodeWithScore]:\n",
    "        q = query.query_str.lower()\n",
    "        \n",
    "        # 1. Seed VALUE nodes mentioned in the query\n",
    "        seeds = [nid for name, nid in self._name2id.items() if name in q]\n",
    "        if not seeds:\n",
    "            print(\"No direct name match found in query. Using first available known metrics as seeds.\")\n",
    "            seeds = list(self._name2id.values())\n",
    "            if not seeds:\n",
    "                return []\n",
    "\n",
    "        # Initialize the lists to collect results during recursion\n",
    "        terminal_value_nodes_output: List[NodeWithScore] = []\n",
    "        equation_nodes_output: List[NodeWithScore] = []\n",
    "        # Sets to track visited nodes and prevent cycles/duplicates\n",
    "        seen_vals: Set[str] = set()\n",
    "        seen_eqs_ids: Set[str] = set()\n",
    "\n",
    "        # 2. Collect results via recursive tree search\n",
    "        for vid in seeds:\n",
    "            self._collect(vid, 0, seen_vals, seen_eqs_ids, terminal_value_nodes_output, equation_nodes_output)\n",
    "\n",
    "        # 3. Combine all collected results\n",
    "        all_results = terminal_value_nodes_output + equation_nodes_output\n",
    "\n",
    "        # 4. Sort the results by score (highest first)\n",
    "        all_results.sort(key=lambda x: x.score, reverse=True)\n",
    "\n",
    "        return all_results\n",
    "\n",
    "    def retrieve(\n",
    "        self,\n",
    "        query: Union[str, QueryBundle],\n",
    "    ) -> List[NodeWithScore]:\n",
    "        \"\"\"Public retrieve method.\"\"\"\n",
    "        # Wrap string into QueryBundle if needed\n",
    "        if not isinstance(query, QueryBundle):\n",
    "            query = QueryBundle(query_str=str(query))\n",
    "        return self._retrieve(query)\n",
    "\n",
    "\n",
    "class CustomGraphQueryEngine(BaseQueryEngine):\n",
    "    \"\"\"\n",
    "    Custom Query Engine that uses CustomGraphRetriever and an LLM to answer queries.\n",
    "    \"\"\"\n",
    "    def __init__(self, retriever: CustomGraphRetriever, llm: OpenAI):\n",
    "        # Pass a default CallbackManager to the superclass constructor\n",
    "        super().__init__(callback_manager=CallbackManager()) \n",
    "        self._retriever = retriever\n",
    "        self._llm = llm\n",
    "        \n",
    "        # Define the prompt template\n",
    "        self._prompt_template = PromptTemplate(\n",
    "            \"\"\"\\\n",
    "Answer the following query using the data and equations.\n",
    "----------------------------------------------------------\n",
    "QUERY:\n",
    "{query_str}\n",
    "----------------------------------------------------------\n",
    "DATA:\n",
    "{supporting_data}\n",
    "----------------------------------------------------------\n",
    "EQUATIONS:\n",
    "{equations}\n",
    "----------------------------------------------------------\n",
    "Concisely answer to the query up to 2 decimal places.\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "    def _get_prompt_modules(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get prompt sub-modules for serialization and prompt management.\"\"\"\n",
    "        return {\"_prompt_template\": self._prompt_template}\n",
    "\n",
    "    def _query(self, query_bundle: QueryBundle) -> Response:\n",
    "        \"\"\"\n",
    "        Executes the query by retrieving nodes, formatting a prompt, and calling the LLM.\n",
    "        \"\"\"\n",
    "        # 1. Call the custom retriever to get relevant nodes\n",
    "        retrieved_nodes: List[NodeWithScore] = self._retriever.retrieve(query_bundle)\n",
    "\n",
    "        supporting_data_list = []\n",
    "        equations_list = []\n",
    "\n",
    "        # 2. Separate retrieved nodes into DATA (VALUE_SENTENCE) and EQUATIONS based on metadata\n",
    "        for node_with_score in retrieved_nodes:\n",
    "            node_type = node_with_score.node.metadata.get(\"node_type\")\n",
    "            if node_type == \"VALUE_SENTENCE\":\n",
    "                supporting_data_list.append(node_with_score.node.text)\n",
    "            elif node_type == \"EQUATION\":\n",
    "                equations_list.append(node_with_score.node.text)\n",
    "\n",
    "        # Join the collected data and equations\n",
    "        supporting_data_str = \"\\n\".join(supporting_data_list) if supporting_data_list else \"No direct supporting data found.\"\n",
    "        equations_str = \"\\n\".join(equations_list) if equations_list else \"No equations found.\"\n",
    "\n",
    "        # 3. Format the prompt using the collected information\n",
    "        formatted_prompt = self._prompt_template.format(\n",
    "            query_str=query_bundle.query_str,\n",
    "            supporting_data=supporting_data_str,\n",
    "            equations=equations_str\n",
    "        )\n",
    "\n",
    "        print(\"formatted_prompt:\\n\", formatted_prompt)\n",
    "\n",
    "        # 4. Call the LLM with the formatted prompt\n",
    "        llm_response = self._llm.complete(formatted_prompt)\n",
    "\n",
    "        # 5. Return the LLM's reply as a LlamaIndex Response object\n",
    "        return Response(response=llm_response.text)\n",
    "\n",
    "    async def _aquery(self, query_bundle: QueryBundle) -> Response:\n",
    "        \"\"\"\n",
    "        Asynchronous query execution (not implemented for this example).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Async query not implemented yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: number of apricots = number of bananas\n",
      "Text: number of apricots = number of bananas\n",
      "Score:  0.500\n",
      "\n",
      "Node ID: number of bananas = number of apples - number of pears\n",
      "Text: number of bananas = number of apples - number of pears\n",
      "Score:  0.250\n",
      "\n",
      "Node ID: apples\n",
      "Text: The following information likely contains the value of apples: -\n",
      "the company Applied Materials (AMAT) has 100 apples\n",
      "Score:  0.200\n",
      "\n",
      "Node ID: pears\n",
      "Text: The following information likely contains the value of pears: -\n",
      "the company Applied Materials (AMAT) has 10 pears\n",
      "Score:  0.200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = CustomGraphRetriever(kgraph, sent_index, name_to_id, max_depth=10)\n",
    "\n",
    "nodes = retriever.retrieve(\n",
    "    \"how many apricots does the company have?\"\n",
    ")\n",
    "\n",
    "[print(n) for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatted_prompt:\n",
      " Answer the following query using the data and equations.\n",
      "----------------------------------------------------------\n",
      "QUERY:\n",
      "how many apricots does the company have?\n",
      "----------------------------------------------------------\n",
      "DATA:\n",
      "The following information likely contains the value of apples:\n",
      "- the company Applied Materials (AMAT) has 100 apples\n",
      "The following information likely contains the value of pears:\n",
      "- the company Applied Materials (AMAT) has 10 pears\n",
      "----------------------------------------------------------\n",
      "EQUATIONS:\n",
      "number of apricots = number of bananas\n",
      "number of bananas = number of apples - number of pears\n",
      "----------------------------------------------------------\n",
      "Concisely answer to the query up to 2 decimal places.\n",
      "\n",
      "The company has 90 apricots.\n"
     ]
    }
   ],
   "source": [
    "query_engine = CustomGraphQueryEngine(retriever, llm=OpenAI(model=\"gpt-4o-mini\", temperature=0))\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"how many apricots does the company have?\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "query_str = \"how many apricots does the company have?\"\n",
    "\n",
    "stream = await llm.astream(PromptTemplate(f\"\"\"\n",
    "Answer the following query using the data and equations.\n",
    "----------------------------------------------------------\n",
    "QUERY:\n",
    "{query_str}\n",
    "----------------------------------------------------------\n",
    "DATA:\n",
    "The company has 102 apples.\n",
    "The company has 30.53 pears.\n",
    "----------------------------------------------------------\n",
    "EQUATIONS:\n",
    "number of apricots = number of bananas\n",
    "number of bananas = number of apples - number of pears\n",
    "----------------------------------------------------------\n",
    "Concisely answer to the query up to 2 decimal places.\n",
    "\"\"\")\n",
    ")\n",
    "\n",
    "\n",
    "async for token in stream:\n",
    "    print(token, end=\"\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
